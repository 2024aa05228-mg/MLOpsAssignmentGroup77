{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2024aa05228-mg/MLOpsAssignmentGroup77/blob/main/MLOps_Assignment2_Group77.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### This block is added to download the dataset only once and to avoid manual download\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "DATASET = \"bhavikjikadara/dog-and-cat-classification-dataset\"\n",
        "DATA_DIR = \"data/raw\"\n",
        "\n",
        "# Read secrets from Colab\n",
        "kaggle_username = userdata.get(\"KAGGLE_USERNAME\")\n",
        "kaggle_key = userdata.get(\"KAGGLE_KEY\")\n",
        "\n",
        "if not kaggle_username or not kaggle_key:\n",
        "    raise RuntimeError(\"Kaggle secrets not found in Colab\")\n",
        "\n",
        "kaggle_creds = {\n",
        "    \"username\": kaggle_username,\n",
        "    \"key\": kaggle_key\n",
        "}\n",
        "\n",
        "# Create BOTH possible Kaggle config paths\n",
        "paths = [\n",
        "    Path.home() / \".kaggle\",\n",
        "    Path.home() / \".config\" / \"kaggle\"\n",
        "]\n",
        "\n",
        "kaggle_config_dir = paths[1] # Set it to ~/.config/kaggle, which is the path mentioned in the error\n",
        "\n",
        "for p in paths:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    kaggle_json = p / \"kaggle.json\"\n",
        "    with open(kaggle_json, \"w\") as f:\n",
        "        json.dump(kaggle_creds, f)\n",
        "    os.chmod(kaggle_json, 0o600)\n",
        "\n",
        "# Set KAGGLE_CONFIG_DIR environment variable to ensure Kaggle API finds the credentials\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = str(kaggle_config_dir)\n",
        "\n",
        "print(\"kaggle.json written to all expected locations and KAGGLE_CONFIG_DIR set.\")\n",
        "\n",
        "# Authenticate\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Download dataset\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "print(\"Downloading dataset...\")\n",
        "api.dataset_download_files(DATASET, path=DATA_DIR, unzip=True)\n",
        "\n",
        "print(\"Dataset downloaded to data/raw/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "-TGtdPrbPOHn",
        "outputId": "c96d5fa5-06cc-4f66-ed9a-8bf7b7134785"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json written to all expected locations and KAGGLE_CONFIG_DIR set.\n",
            "Downloading dataset...\n",
            "Dataset URL: https://www.kaggle.com/datasets/bhavikjikadara/dog-and-cat-classification-dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "KaggleHttpClient.call() got an unexpected keyword argument 'headers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1622334602.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munzip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset downloaded to data/raw/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mdataset_download_files\u001b[0;34m(self, dataset, path, force, quiet, unzip, licenses)\u001b[0m\n\u001b[1;32m   1666\u001b[0m       \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffective_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_slug\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1668\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1669\u001b[0m         \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, response, outfile, http_client, quiet, resume, chunk_size)\u001b[0m\n\u001b[1;32m   2145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m       \u001b[0mrequest_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m       response = http_client.call(\n\u001b[0m\u001b[1;32m   2148\u001b[0m           \u001b[0mrequest_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m           \u001b[0mrequest_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: KaggleHttpClient.call() got an unexpected keyword argument 'headers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms # Added this import statement\n",
        "\n",
        "RAW_DIR = \"/content/data/raw/PetImages\"\n",
        "PROCESSED_DIR = \"data/processed\"\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "for label in [\"cat\", \"dog\"]: # Changed labels to lowercase\n",
        "    input_dir = os.path.join(RAW_DIR, label.capitalize()) # Original raw data has 'Cat' and 'Dog'\n",
        "    output_dir = os.path.join(PROCESSED_DIR, label)\n",
        "    os.makedirs(input_dir, exist_ok=True) # Create raw input directories if they don't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Only proceed if input_dir is not empty to avoid errors on empty directories\n",
        "    if os.listdir(input_dir):\n",
        "        for img_name in os.listdir(input_dir):\n",
        "            img_path = os.path.join(input_dir, img_name)\n",
        "            try:\n",
        "                img = Image.open(img_path).convert(\"RGB\")\n",
        "                img = img.resize(IMG_SIZE)\n",
        "                img.save(os.path.join(output_dir, img_name))\n",
        "            except Exception as e:\n",
        "                print(f\"Could not process image {img_name} in {input_dir}: {e}\")\n",
        "    else:\n",
        "        print(f\"Warning: '{input_dir}' is empty. No images to process for this label.\")\n",
        "\n",
        "print(\"Preprocessing completed\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq2uKirRNrKu",
        "outputId": "6c753589-12e1-4b9d-f829-7e84e901cb2d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports & Model definition\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "import os"
      ],
      "metadata": {
        "id": "vWdpPlZRb1o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # Keep existing imports for context\n",
        "from torchvision import datasets, transforms # Add transforms import\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "PROCESSED_DIR = \"data/processed\" # Define PROCESSED_DIR in this cell\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(PROCESSED_DIR, transform=transform)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "Y9Gyw9H2cAy6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "\n",
        "class BaselineCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 54 * 54, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(self.conv(x))\n",
        "\n",
        "model = BaselineCNN()\n",
        "os.makedirs('models', exist_ok=True)\n",
        "torch.save(model.state_dict(), \"models/baseline_cnn.pt\")\n",
        "\n",
        "!pip install mlflow\n",
        "!mlflow ui\n",
        "\n",
        "\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "mlflow.set_experiment(\"cats_vs_dogs_baseline\")\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_param(\"learning_rate\", 0.001)\n",
        "    mlflow.log_param(\"epochs\", 10)\n",
        "    mlflow.log_param(\"batch_size\", 32)\n",
        "\n",
        "    mlflow.log_metric(\"train_loss\", train_loss)\n",
        "    mlflow.log_metric(\"val_accuracy\", val_acc)\n",
        "\n",
        "    mlflow.pytorch.log_model(model, \"baseline_cnn\")\n",
        "\n",
        "\n",
        "    mlflow.log_artifact(\"outputs/confusion_matrix.png\")\n",
        "mlflow.log_artifact(\"outputs/loss_curve.png\")"
      ],
      "metadata": {
        "id": "aUDCVL-cFdRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37750599-aea9-475a-b585-8ad600e0f9c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.9.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-skinny==3.9.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.9.0-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting mlflow-tracing==3.9.0 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.9.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask-CORS<7 (from mlflow)\n",
            "  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.18.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting huey<3,>=2.5.4 (from mlflow)\n",
            "  Downloading huey-2.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Collecting skops<1 (from mlflow)\n",
            "  Downloading skops-0.13.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.46)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (6.2.6)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.2)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.9.0->mlflow)\n",
            "  Downloading databricks_sdk-0.84.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.123.10)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.46)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.7.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.5.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.40.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.5)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.3.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: prettytable>=3.9 in /usr/local/lib/python3.12/dist-packages (from skops<1->mlflow) (3.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (3.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (2.47.0)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.50.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.9.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.9.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable>=3.9->skops<1->mlflow) (0.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (2026.1.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.9.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.9.0->mlflow) (4.12.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.6.2)\n",
            "Downloading mlflow-3.9.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.9.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.9.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huey-2.6.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading skops-0.13.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.84.0-py3-none-any.whl (796 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: huey, gunicorn, graphql-core, graphql-relay, docker, skops, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "Successfully installed Flask-CORS-6.0.2 databricks-sdk-0.84.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.6.0 mlflow-3.9.0 mlflow-skinny-3.9.0 mlflow-tracing-3.9.0 skops-0.13.0\n",
            "Backend store URI not provided. Using sqlite:///mlflow.db\n",
            "Registry store URI not provided. Using backend store URI.\n",
            "2026/02/04 17:48:37 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
            "2026/02/04 17:48:37 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
            "2026/02/04 17:48:37 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
            "2026/02/04 17:48:37 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
            "2026/02/04 17:48:37 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
            "2026/02/04 17:48:37 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
            "2026/02/04 17:48:37 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2026/02/04 17:48:37 INFO mlflow.store.db.utils: Updating database tables\n",
            "2026/02/04 17:48:37 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/02/04 17:48:37 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
            "2026/02/04 17:48:38 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade 1bd49d398cd23 -> b7c8d9e0f1a2, add trace metrics table\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade b7c8d9e0f1a2 -> 5d2d30f0abce, update job table\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade 5d2d30f0abce -> c9d4e5f6a7b8, add routing strategy to endpoints and linkage type to mappings\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade c9d4e5f6a7b8 -> 2c33131f4dae, add online_scoring_configs table\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Running upgrade 2c33131f4dae -> d3e4f5a6b7c8, add display_name to endpoint_bindings\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/02/04 17:48:39 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "[MLflow] Security middleware enabled with default settings (localhost-only). To allow connections from other hosts, use --host 0.0.0.0 and configure --allowed-hosts and --cors-allowed-origins.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:5000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Started parent process [\u001b[36m\u001b[1m6054\u001b[0m]\n",
            "2026/02/04 17:48:54 INFO mlflow.server.jobs.utils: Starting huey consumer for job function run_online_session_scorer\n",
            "2026/02/04 17:48:54 INFO mlflow.server.jobs.utils: Starting huey consumer for job function run_online_trace_scorer\n",
            "2026/02/04 17:48:54 INFO mlflow.server.jobs.utils: Starting huey consumer for job function invoke_scorer\n",
            "2026/02/04 17:48:54 INFO mlflow.server.jobs.utils: Starting dedicated Huey consumer for periodic tasks\n",
            "2026/02/04 17:48:57 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
            "2026/02/04 17:48:57 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
            "2026/02/04 17:48:57 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
            "2026/02/04 17:48:57 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
            "2026/02/04 17:48:57 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
            "2026/02/04 17:48:57 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
            "2026/02/04 17:48:58 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m6060\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "2026/02/04 17:49:00 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
            "2026/02/04 17:49:00 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
            "2026/02/04 17:49:00 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
            "2026/02/04 17:49:00 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
            "2026/02/04 17:49:00 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
            "2026/02/04 17:49:00 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m6059\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m6057\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m6058\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "2026/02/04 17:49:06 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
            "2026/02/04 17:49:06 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
            "2026/02/04 17:49:06 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
            "2026/02/04 17:49:06 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
            "2026/02/04 17:49:06 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
            "2026/02/04 17:49:06 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
            "2026/02/04 17:49:09 INFO mlflow.server.jobs.utils: Registered online_scoring_scheduler periodic task (runs every 1 minute)\n",
            "[2026-02-04 17:49:09,464] INFO:huey.consumer:MainThread:Huey consumer started with 5 thread, PID 6168 at 2026-02-04 17:49:09.464054\n",
            "[2026-02-04 17:49:09,465] INFO:huey.consumer:MainThread:Scheduler runs every 1 second(s).\n",
            "[2026-02-04 17:49:09,745] INFO:huey.consumer:MainThread:Huey consumer started with 5 thread, PID 6165 at 2026-02-04 17:49:09.745684\n",
            "[2026-02-04 17:49:09,746] INFO:huey.consumer:MainThread:Scheduler runs every 1 second(s).\n",
            "[2026-02-04 17:49:09,466] INFO:huey.consumer:MainThread:Periodic tasks are enabled.\n",
            "[2026-02-04 17:49:09,789] INFO:huey.consumer:MainThread:The following commands are available:\n",
            "+ mlflow.server.jobs.utils._exec_job\n",
            "+ mlflow.server.jobs.utils.online_scoring_scheduler\n",
            "[2026-02-04 17:49:09,791] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 6b7eed17-1553-4c73-afb6-82a257b992a2.\n",
            "[2026-02-04 17:49:09,803] INFO:huey:Worker-3:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 6b7eed17-1553-4c73-afb6-82a257b992a2\n",
            "[2026-02-04 17:49:09,749] INFO:huey.consumer:MainThread:Periodic tasks are enabled.\n",
            "[2026-02-04 17:49:10,096] INFO:huey.consumer:MainThread:The following commands are available:\n",
            "+ mlflow.server.jobs.utils._exec_job\n",
            "[2026-02-04 17:49:10,272] INFO:huey.consumer:MainThread:Huey consumer started with 5 thread, PID 6162 at 2026-02-04 17:49:10.272497\n",
            "[2026-02-04 17:49:10,273] INFO:huey.consumer:MainThread:Scheduler runs every 1 second(s).\n",
            "[2026-02-04 17:49:10,311] INFO:huey.consumer:MainThread:Huey consumer started with 10 thread, PID 6166 at 2026-02-04 17:49:10.311693\n",
            "[2026-02-04 17:49:10,311] INFO:huey.consumer:MainThread:Scheduler runs every 1 second(s).\n",
            "[2026-02-04 17:49:10,313] INFO:huey.consumer:MainThread:Periodic tasks are enabled.\n",
            "[2026-02-04 17:49:10,313] INFO:huey.consumer:MainThread:The following commands are available:\n",
            "+ mlflow.server.jobs.utils._exec_job\n",
            "[2026-02-04 17:49:10,276] INFO:huey.consumer:MainThread:Periodic tasks are enabled.\n",
            "[2026-02-04 17:49:10,490] INFO:huey.consumer:MainThread:The following commands are available:\n",
            "+ mlflow.server.jobs.utils._exec_job\n",
            "2026/02/04 17:49:10 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
            "2026/02/04 17:49:10 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
            "2026/02/04 17:49:10 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
            "2026/02/04 17:49:10 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
            "2026/02/04 17:49:10 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
            "2026/02/04 17:49:10 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
            "[2026-02-04 17:49:11,403] INFO:huey:Worker-3:mlflow.server.jobs.utils.online_scoring_scheduler: 6b7eed17-1553-4c73-afb6-82a257b992a2 executed in 1.600s\n",
            "[2026-02-04 17:50:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 78e12058-cca3-4e0a-9229-9a614ae8ed1f.\n",
            "[2026-02-04 17:50:16,315] INFO:huey:Worker-2:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 78e12058-cca3-4e0a-9229-9a614ae8ed1f\n",
            "[2026-02-04 17:50:16,318] INFO:huey:Worker-2:mlflow.server.jobs.utils.online_scoring_scheduler: 78e12058-cca3-4e0a-9229-9a614ae8ed1f executed in 0.003s\n",
            "[2026-02-04 17:51:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 3bd10496-a4a3-4305-8d0b-b65a5f0b8a92.\n",
            "[2026-02-04 17:51:14,038] INFO:huey:Worker-2:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 3bd10496-a4a3-4305-8d0b-b65a5f0b8a92\n",
            "[2026-02-04 17:51:14,042] INFO:huey:Worker-2:mlflow.server.jobs.utils.online_scoring_scheduler: 3bd10496-a4a3-4305-8d0b-b65a5f0b8a92 executed in 0.004s\n",
            "[2026-02-04 17:52:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: f5d8cfe2-4d80-45d5-9a44-aa62cf191bb8.\n",
            "[2026-02-04 17:52:11,760] INFO:huey:Worker-2:Executing mlflow.server.jobs.utils.online_scoring_scheduler: f5d8cfe2-4d80-45d5-9a44-aa62cf191bb8\n",
            "[2026-02-04 17:52:11,765] INFO:huey:Worker-2:mlflow.server.jobs.utils.online_scoring_scheduler: f5d8cfe2-4d80-45d5-9a44-aa62cf191bb8 executed in 0.004s\n",
            "[2026-02-04 17:53:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: e9948693-5b22-4602-b0ae-91aad04c1fc4.\n",
            "[2026-02-04 17:53:09,483] INFO:huey:Worker-2:Executing mlflow.server.jobs.utils.online_scoring_scheduler: e9948693-5b22-4602-b0ae-91aad04c1fc4\n",
            "[2026-02-04 17:53:09,487] INFO:huey:Worker-2:mlflow.server.jobs.utils.online_scoring_scheduler: e9948693-5b22-4602-b0ae-91aad04c1fc4 executed in 0.003s\n",
            "[2026-02-04 17:54:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: f2047aeb-b5bb-4d3b-b365-a5dc35680f10.\n",
            "[2026-02-04 17:54:15,963] INFO:huey:Worker-2:Executing mlflow.server.jobs.utils.online_scoring_scheduler: f2047aeb-b5bb-4d3b-b365-a5dc35680f10\n",
            "[2026-02-04 17:54:15,973] INFO:huey:Worker-2:mlflow.server.jobs.utils.online_scoring_scheduler: f2047aeb-b5bb-4d3b-b365-a5dc35680f10 executed in 0.010s\n",
            "[2026-02-04 17:55:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: d2eb4626-ebbe-4e83-b35a-c712b8d55f73.\n",
            "[2026-02-04 17:55:13,693] INFO:huey:Worker-2:Executing mlflow.server.jobs.utils.online_scoring_scheduler: d2eb4626-ebbe-4e83-b35a-c712b8d55f73\n",
            "[2026-02-04 17:55:13,697] INFO:huey:Worker-2:mlflow.server.jobs.utils.online_scoring_scheduler: d2eb4626-ebbe-4e83-b35a-c712b8d55f73 executed in 0.004s\n",
            "[2026-02-04 17:56:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 6d9c4851-7309-4e9c-972e-4cfc426c6ee8.\n",
            "[2026-02-04 17:56:11,416] INFO:huey:Worker-2:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 6d9c4851-7309-4e9c-972e-4cfc426c6ee8\n",
            "[2026-02-04 17:56:11,419] INFO:huey:Worker-2:mlflow.server.jobs.utils.online_scoring_scheduler: 6d9c4851-7309-4e9c-972e-4cfc426c6ee8 executed in 0.003s\n",
            "[2026-02-04 17:57:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 41401164-d6d1-4f91-b8df-9153875df7cf.\n",
            "[2026-02-04 17:57:16,331] INFO:huey:Worker-1:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 41401164-d6d1-4f91-b8df-9153875df7cf\n",
            "[2026-02-04 17:57:16,338] INFO:huey:Worker-1:mlflow.server.jobs.utils.online_scoring_scheduler: 41401164-d6d1-4f91-b8df-9153875df7cf executed in 0.007s\n",
            "[2026-02-04 17:58:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 6898726a-df3b-434d-911c-87bb593c6a81.\n",
            "[2026-02-04 17:58:14,058] INFO:huey:Worker-1:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 6898726a-df3b-434d-911c-87bb593c6a81\n",
            "[2026-02-04 17:58:14,062] INFO:huey:Worker-1:mlflow.server.jobs.utils.online_scoring_scheduler: 6898726a-df3b-434d-911c-87bb593c6a81 executed in 0.004s\n",
            "[2026-02-04 17:59:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 29010740-6718-41cb-98d3-cea1291bcbfe.\n",
            "[2026-02-04 17:59:11,783] INFO:huey:Worker-1:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 29010740-6718-41cb-98d3-cea1291bcbfe\n",
            "[2026-02-04 17:59:11,787] INFO:huey:Worker-1:mlflow.server.jobs.utils.online_scoring_scheduler: 29010740-6718-41cb-98d3-cea1291bcbfe executed in 0.004s\n",
            "[2026-02-04 18:00:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 9a87952c-ef58-4c08-a7f9-97d014a9a974.\n",
            "[2026-02-04 18:00:09,506] INFO:huey:Worker-1:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 9a87952c-ef58-4c08-a7f9-97d014a9a974\n",
            "[2026-02-04 18:00:09,509] INFO:huey:Worker-1:mlflow.server.jobs.utils.online_scoring_scheduler: 9a87952c-ef58-4c08-a7f9-97d014a9a974 executed in 0.003s\n",
            "[2026-02-04 18:01:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: f8e85e73-2888-45c4-998b-4e50ea69b729.\n",
            "[2026-02-04 18:01:15,985] INFO:huey:Worker-1:Executing mlflow.server.jobs.utils.online_scoring_scheduler: f8e85e73-2888-45c4-998b-4e50ea69b729\n",
            "[2026-02-04 18:01:15,989] INFO:huey:Worker-1:mlflow.server.jobs.utils.online_scoring_scheduler: f8e85e73-2888-45c4-998b-4e50ea69b729 executed in 0.004s\n",
            "[2026-02-04 18:02:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 00edb0cd-9d99-4805-991f-2127967806ca.\n",
            "[2026-02-04 18:02:13,709] INFO:huey:Worker-1:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 00edb0cd-9d99-4805-991f-2127967806ca\n",
            "[2026-02-04 18:02:13,712] INFO:huey:Worker-1:mlflow.server.jobs.utils.online_scoring_scheduler: 00edb0cd-9d99-4805-991f-2127967806ca executed in 0.003s\n",
            "[2026-02-04 18:03:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 0a28bff0-4fac-477e-9a21-d756c7cc2093.\n",
            "[2026-02-04 18:03:11,431] INFO:huey:Worker-1:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 0a28bff0-4fac-477e-9a21-d756c7cc2093\n",
            "[2026-02-04 18:03:11,436] INFO:huey:Worker-1:mlflow.server.jobs.utils.online_scoring_scheduler: 0a28bff0-4fac-477e-9a21-d756c7cc2093 executed in 0.005s\n",
            "[2026-02-04 18:04:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 62643c4d-0fbf-4885-9ae0-3d665f567b60.\n",
            "[2026-02-04 18:04:16,399] INFO:huey:Worker-4:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 62643c4d-0fbf-4885-9ae0-3d665f567b60\n",
            "[2026-02-04 18:04:16,406] INFO:huey:Worker-4:mlflow.server.jobs.utils.online_scoring_scheduler: 62643c4d-0fbf-4885-9ae0-3d665f567b60 executed in 0.007s\n",
            "[2026-02-04 18:05:09,464] INFO:huey.consumer.Scheduler:Scheduler:Enqueueing periodic task mlflow.server.jobs.utils.online_scoring_scheduler: 85f810f8-fc24-4c7c-9052-25f340db98a0.\n",
            "[2026-02-04 18:05:14,125] INFO:huey:Worker-4:Executing mlflow.server.jobs.utils.online_scoring_scheduler: 85f810f8-fc24-4c7c-9052-25f340db98a0\n",
            "[2026-02-04 18:05:14,129] INFO:huey:Worker-4:mlflow.server.jobs.utils.online_scoring_scheduler: 85f810f8-fc24-4c7c-9052-25f340db98a0 executed in 0.004s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}